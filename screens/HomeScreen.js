import React, { useState, useEffect, useRef } from 'react';
import { View, StyleSheet, Dimensions, Text } from 'react-native';
import { CameraView, useCameraPermissions } from 'expo-camera';  // â† CameraView ë¡œ ë³€ê²½
import { useIsFocused } from '@react-navigation/native';
import Svg, { Rect, Text as SvgText } from 'react-native-svg';
import io from 'socket.io-client';
import * as Speech from 'expo-speech';  // â† ìƒë‹¨ì— ì¶”ê°€
import { LoadSpeechInfo } from "../utils/speech/LoadSpeechInfo";

const { width: previewWidth, height: previewHeight } = Dimensions.get('window');
const SERVER_URL = 'IPì£¼ì†Œ';  // ë³¸ì¸ ì„œë²„ IP:í¬íŠ¸

export default function HomeScreen({navigation}) {
  const [rate, setRate] = useState(1.0);
  const [pitch, setPitch] = useState(1.0);
  const [loaded, setLoaded] = useState(false);

  const cameraRef = useRef(null);
  const socketRef = useRef(null);
  const isFocused = useIsFocused();

  const [permission, requestPermission] = useCameraPermissions();
  const [detections, setDetections] = useState([]);
  const [photoSize, setPhotoSize] = useState({ width: 1, height: 1 });
  const [frameReady, setFrameReady] = useState(true);

  // ìŒì„± ì„¤ì • useEffect ë¨¼ì € ì„¤ì •ì„ ìœ„í•´ì„œ
  useEffect(() => {
      const loadTTSInfo = async () => {
        await LoadSpeechInfo(setRate, setPitch);
        setLoaded(true); 
      }
      
      loadTTSInfo();
    }, [navigation]);

  // 2. Socket.IO ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
  useEffect(() => {
    console.log("ê°ì²´ ì¸ì‹",rate, pitch);
    const sock = io(SERVER_URL, { transports: ['websocket'], reconnection: true });
    socketRef.current = sock;
    sock.on('connect',    () => console.log('âœ… Socket connected'));
    sock.on('disconnect', () => console.log('âŒ Socket disconnected'));
    sock.on('detection',  data => {
      console.log('ğŸ–¼ï¸ Received detections', data);
      setDetections(data);

      // â• ì¶”ê°€ëœ ë¶€ë¶„: ì¤‘ë³µ ì œê±°ëœ class_name ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
      const uniqueClasses = [...new Set(data.map(item => item.class_name))];

      if (uniqueClasses.length > 0) {
        const message = uniqueClasses.join(', ') + ' ê°ì§€ë¨';
        Speech.speak(message, { language: 'ko-KR', rate: rate, pitch: pitch});
      }
    });
    return () => sock.disconnect();
  }, [loaded]);

  // 2) ìë™ í”„ë ˆì„ ì „ì†¡ (ê¶Œí•œÂ·í¬ì»¤ìŠ¤ í™•ì¸)
  useEffect(() => {
    if (!permission?.granted || !isFocused) return;

    const interval = setInterval(async () => {
      if (!frameReady) return;
      setFrameReady(false);

      try {
        const photo = await cameraRef.current.takePictureAsync({
          base64: true,
          quality: 0.3,
        });
        // ì›ë³¸ í•´ìƒë„ ì €ì¥
        setPhotoSize({ width: photo.width, height: photo.height });

        // ì„œë²„ì— ì´ë¯¸ì§€ + í•´ìƒë„ ì „ì†¡
        // 1. ì‚¬ì§„ ì´¬ì˜ â†’ ì„œë²„ì— ì „ì†¡
        // 2. ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨í•˜ë”ë¼ë„
        // 3. ì¼ì • ì‹œê°„ í›„ì— ë‹¤ìŒ í”„ë ˆì„ ì´¬ì˜ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        const imgData = 'data:image/jpeg;base64,' + photo.base64;
        socketRef.current.emit('image', {
          image: imgData,
          width: photo.width,
          height: photo.height,
        });
        console.log('ğŸ“¤ Frame sent');
      } catch (e) {
        console.error('ğŸš« sendFrame error', e);
      } finally {
        setTimeout(() => setFrameReady(true), 1000); // ë‹¤ìŒ í”„ë ˆì„ ì¤€ë¹„ê¹Œì§€ ëŒ€ê¸° ì‹œê°„
      }
    }, 1000); // sendFrame ì‹¤í–‰ ì£¼ê¸°

    return () => clearInterval(interval);
  }, [permission, isFocused, frameReady]);

  // 3) ê¶Œí•œ ìš”ì²­ UI
  if (!permission) return <View />;
  if (!permission.granted) {
    return (
      <View style={styles.center}>
        <Text onPress={requestPermission} style={styles.link}>
          ì¹´ë©”ë¼ ê¶Œí•œ ìš”ì²­
        </Text>
      </View>
    );
  }

  // 4) ë Œë”ë§: CameraView + ë°•ìŠ¤ ì˜¤ë²„ë ˆì´
  return (
    <View style={styles.container}>
      {isFocused && <CameraView style={styles.camera} ref={cameraRef} />}
      <Svg style={StyleSheet.absoluteFill} pointerEvents="none">
        {detections.map((item, idx) => {
          // í™”ë©´ ë¹„ìœ¨ ê³„ì‚°
          const scaleX = previewWidth  / photoSize.width;
          const scaleY = previewHeight / photoSize.height;

          // ìŠ¤ì¼€ì¼ë§ëœ ì¢Œí‘œ
          const x = item.bbox[0] * scaleX;
          const y = item.bbox[1] * scaleY;
          const w = (item.bbox[2] - item.bbox[0]) * scaleX;
          const h = (item.bbox[3] - item.bbox[1]) * scaleY;

          return (
            <React.Fragment key={idx}>
              <Rect
                x={x} y={y}
                width={w} height={h}
                stroke="lime" strokeWidth={2} fill="transparent"
              />
              <SvgText
                x={x + 4} y={y - 6}
                fontSize={14} fontWeight="bold" fill="lime"
              >
                {`${item.class_name} (${item.confidence})`}
              </SvgText>
            </React.Fragment>
          );
        })}
      </Svg>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1 },
  camera:    { flex: 1 },
  center:    { flex: 1, justifyContent: 'center', alignItems: 'center' },
  link:      { fontSize: 18, color: 'blue', textDecorationLine: 'underline' },
});