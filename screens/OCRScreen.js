import React, { useState, useRef, useEffect } from 'react';
import { View, Text, Button, StyleSheet, Touchable, TouchableOpacity } from 'react-native';
import { CameraView, useCameraPermissions } from 'expo-camera';
import { useIsFocused } from '@react-navigation/native';
import * as Speech from 'expo-speech';
import { Header } from 'react-native/Libraries/NewAppScreen';

const OCRScreen = ({route, navigation}) => {
  //const {rate, pitch} = route.params;
  const [facing, setFacing] = useState('back');
  const [permission, requestPermission] = useCameraPermissions();
  const isFocused = useIsFocused();
  const [image, setImage] = useState(null);
  const cameraRef = useRef(null);
  const [disabled, SetDisabled] = useState(false); // ë²„íŠ¼ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ì„œ

  // ë¬¸ì ì¸ì‹ ì§„ì…í•˜ë©´ ì•ˆë‚´í•˜ëŠ” TTS
  useEffect(() => {
    console.log("OCR í™”ë©´");

    const StartTTS = navigation.addListener("focus", () => {
      Speech.speak("ê¸€ì ì¸ì‹", {
        //rate: rate,
        //pitch: pitch
      });
    });

    return StartTTS;
  }, [navigation]);

  // ì¹´ë©”ë¼ ê¶Œí•œì— í•„ìš”í•œ ê³¼ì •
  if (!permission) {
    return <View />;
  }

  if (!permission.granted) {
    return (
      <View style={styles.container}>
        <Text style={styles.message}>ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.</Text>
        <Button onPress={requestPermission} title="ê¶Œí•œ í—ˆìš©" />
      </View>
    );
  }

// ì‚¬ì§„ ì°ëŠ” í•¨ìˆ˜
  const takePicture = async() =>{
    let photo = null;

    if(cameraRef.current){
      SetDisabled(true); // ë²„íŠ¼ ëˆ„ë¥´ë©´ ë²„íŠ¼ ë¹„í™œì„±í™”
      photo = await cameraRef.current.takePictureAsync({ base64: false });
      setImage(photo);
      console.log(`[${new Date().toISOString()}] ğŸ“¤ ì „ì†¡ ì‹œì‘`);
      Speech.speak("ê¸€ì ì¸ì‹ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.", {
        language: 'ko-KR',
        //rate: rate,
        //pitch:pitch
      });
    }
    
    const formData = new FormData();
      formData.append('image', {
        uri: photo.uri,
        name: 'OCR.jpg',
        type: 'image/jpeg',
      });
      
    try{
      const response = await fetch('IPì£¼ì†Œ/ocr/image', {
        method: "POST",
        body: formData,
        headers: {
          "Content-Type" : "multipart/form-data",
        }
      })

    if (response.ok) {
      const result = await response.json(); // ì„œë²„ê°€ JSON ì‘ë‹µì„ ì¤„ ê²½ìš°
      console.log(`[${new Date().toISOString()}] ì‚¬ì§„ ì „ì†¡ ì„±ê³µ:`, result);
      Speech.speak(result.translated_text || 'ì¸ì‹ëœ ê¸€ìê°€ ì—†ìŠµë‹ˆë‹¤ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.', {
          language: 'ko-KR',
          //rate: rate,
          //pitch: pitch
        });
    } else {
      Speech.speak("ì˜¤ë¥˜ê°€ ë°œìƒ." + "ê¸€ì ì¸ì‹ ì‹¤íŒ¨",{
          language: 'ko-KR',
          //rate: rate,
          //pitch:pitch
        })
      console.warn("ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨:", response.status);
      const errorText = await response.text();
      console.warn("ì„œë²„ ì‘ë‹µ ë‚´ìš©:", errorText);
    }
    }catch(error){
      console.error("OCR ì—…ë¡œë“œ ì‹¤íŒ¨:", error);
    }
    SetDisabled(false); // ê²°ê³¼ ì¶œë ¥ë˜ë©´ ë²„íŠ¼ í™œì„±í™”
  }

  // í™”ë©´ êµ¬ì„±
  return (
    <View style={styles.container}>
      {/* í™”ë©´ì´ í¬ì»¤ìŠ¤ ë˜ì—ˆì„ ë•Œë§Œ ì¹´ë©”ë¼ ë Œë”ë§ */}
      {isFocused ? (
        <>
        <CameraView 
        style={styles.camera} 
        facing={facing}
        ref={cameraRef}/>
        {/* CameraViewì—ëŠ” ìì‹ ì»´í¬ë„ŒíŠ¸ë¥¼ ë‘˜ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ë²„íŠ¼ì„ ë”°ë¡œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.*/}
        {/* ì¹´ë©”ë¼ì™€ ê²¹ì¹˜ê²Œ í•˜ëŠ” ë°©ë²•ì´ ìµœì„ (ì ˆëŒ€ì ì¸ ìœ„ì¹˜ë¥¼ ê°™ê²Œ ë§Œë“ ë‹¤*/}
        {/*buttonContainerì™€  buttonë¥¼ ì°¸ê³ í•´ì„œ í•œë‹¤.*/}
        <View style={styles.buttonContainer}>
          <TouchableOpacity style = {styles.button} onPress = {takePicture} disabled={disabled}> 
            <Text style={styles.text}>ê¸€ì ì¸ì‹</Text>
          </TouchableOpacity>
        </View>
        </>
      ) : (
        // ë¹ˆ ë·°ë¡œ ëŒ€ì²´í•˜ì—¬ ë©”ëª¨ë¦¬ í•´ì œ ë„ì™€ì¤€ë‹¤. 
        <View style={styles.camera} />
      )}
    </View>
  );
};
/*
*/
export default OCRScreen;


const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
  },
  message: {
    textAlign: 'center',
    paddingBottom: 10,
  },
  camera: {
    flex: 1,
  },
  buttonContainer: {
    position: 'absolute',
    bottom: 40,
    left: 0,
    right: 0,
    alignItems: 'center',
  },
  button: {
    backgroundColor: '#1e90ff',
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 10,
  },
  text: {
    fontSize: 24,
    fontWeight: 'bold',
    color: 'black',
  },
  OCRresult: {
    position: 'absolute',
    fontsize: 24
  },
});